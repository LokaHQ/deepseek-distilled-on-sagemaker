hf_model_id = "deepseek-ai/DeepSeek-R1-Distill-Llama-8B" # E.x. deepseek-ai/DeepSeek-R1-Distill-Llama-8B
role_arn = 'arn:aws:iam::[account_id]:role/service-role/[AmazonSageMaker-ExecutionRole-xxxxxxxxxxxxxxx]' # Please make sure it has sufficient permission as listed in the pre-requisite
region_info = 'us-west-2' # You can modify to 'us-east-1' based on your need # Region (currently only 'us-west-2' and 'us-east-1' support CMI with Deepseek-Distilled-Llama models)
instance_type = 'ml.g6.2xlarge' # Instance type for deployment
initial_instance_count = 1 # Initial instance count for deployment
container_startup_health_check_timeout = 600 # Timeout for container startup health check
sm_num_gpus = 1 # Number of GPUs to use